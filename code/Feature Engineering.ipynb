{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f164de44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0f2efcea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26664 entries, 0 to 26663\n",
      "Data columns (total 25 columns):\n",
      " #   Column                      Non-Null Count  Dtype \n",
      "---  ------                      --------------  ----- \n",
      " 0   ID                          26664 non-null  object\n",
      " 1   LIMIT_BAL                   26664 non-null  int64 \n",
      " 2   SEX                         26664 non-null  int64 \n",
      " 3   EDUCATION                   26664 non-null  int64 \n",
      " 4   MARRIAGE                    26664 non-null  int64 \n",
      " 5   AGE                         26664 non-null  int64 \n",
      " 6   PAY_1                       26664 non-null  int64 \n",
      " 7   PAY_2                       26664 non-null  int64 \n",
      " 8   PAY_3                       26664 non-null  int64 \n",
      " 9   PAY_4                       26664 non-null  int64 \n",
      " 10  PAY_5                       26664 non-null  int64 \n",
      " 11  PAY_6                       26664 non-null  int64 \n",
      " 12  BILL_AMT1                   26664 non-null  int64 \n",
      " 13  BILL_AMT2                   26664 non-null  int64 \n",
      " 14  BILL_AMT3                   26664 non-null  int64 \n",
      " 15  BILL_AMT4                   26664 non-null  int64 \n",
      " 16  BILL_AMT5                   26664 non-null  int64 \n",
      " 17  BILL_AMT6                   26664 non-null  int64 \n",
      " 18  PAY_AMT1                    26664 non-null  int64 \n",
      " 19  PAY_AMT2                    26664 non-null  int64 \n",
      " 20  PAY_AMT3                    26664 non-null  int64 \n",
      " 21  PAY_AMT4                    26664 non-null  int64 \n",
      " 22  PAY_AMT5                    26664 non-null  int64 \n",
      " 23  PAY_AMT6                    26664 non-null  int64 \n",
      " 24  default payment next month  26664 non-null  int64 \n",
      "dtypes: int64(24), object(1)\n",
      "memory usage: 5.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('cleaned_data_0.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f903a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Non_features = ['ID','default payment next month','PAY_5','PAY_6','BILL_AMT2','BILL_AMT3','BILL_AMT4','BILL_AMT5','BILL_AMT6']\n",
    "X = df.drop(columns=Non_features).values\n",
    "Y = df.iloc[:,24].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02b50ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26664, 29) (26664,)\n"
     ]
    }
   ],
   "source": [
    "scale = StandardScaler()\n",
    "\n",
    "X_scale = scale.fit_transform(X)\n",
    "Y_scale = Y.ravel()\n",
    "\n",
    "print(X_scale.shape,Y_scale.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "35afd3a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26664, 16) (26664,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scale = RobustScaler()\n",
    "X_scale = scale.fit_transform(X)\n",
    "Y_scale = Y.ravel()\n",
    "\n",
    "print(X_scale.shape,Y_scale.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fca1e3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scale, Y_scale, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "5cc7bfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# use a full grid over all parameters\n",
    "param_grid = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [1, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3677038e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/haoli/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "360 fits failed out of a total of 1080.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/haoli/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/haoli/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"/Users/haoli/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/haoli/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/haoli/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/haoli/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/haoli/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/haoli/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/haoli/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/haoli/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/haoli/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"/Users/haoli/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/haoli/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "180 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/haoli/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/haoli/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"/Users/haoli/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/haoli/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/haoli/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/haoli/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/haoli/opt/anaconda3/lib/python3.8/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/haoli/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/haoli/opt/anaconda3/lib/python3.8/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/haoli/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/haoli/opt/anaconda3/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\", line 187, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"/Users/haoli/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/haoli/opt/anaconda3/lib/python3.8/site-packages/sklearn/tree/_classes.py\", line 250, in fit\n",
      "    raise ValueError(\n",
      "ValueError: min_samples_split must be an integer greater than 1 or a float in (0.0, 1.0]; got the integer 1\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/haoli/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.77900689 0.77952265        nan 0.7796633  0.78092899\n",
      "        nan 0.77858502 0.777882          nan 0.80671323 0.80619765\n",
      "        nan 0.80746332 0.80479113        nan 0.80624456 0.80605695\n",
      "        nan 0.82012082 0.82030832        nan 0.81979274 0.82026153\n",
      "        nan 0.81993336 0.8199802         nan 0.8112606  0.81111993\n",
      "        nan 0.81191688 0.81355776        nan 0.80929181 0.80990124\n",
      "        nan 0.81182314 0.81707367        nan 0.81590171 0.81777683\n",
      "        nan 0.8179175  0.81707371        nan 0.8105575  0.81426092\n",
      "        nan 0.81604241 0.81669866        nan 0.81716735 0.81791743\n",
      "        nan 0.77788183 0.77731941        nan 0.77783509 0.77731937\n",
      "        nan 0.78027285 0.7788194         nan 0.80540058 0.80638507\n",
      "        nan 0.80554121 0.80493165        nan 0.8040412  0.80441612\n",
      "        nan 0.81923024 0.81885511        nan 0.81932396 0.81932384\n",
      "        nan 0.81969892 0.81908954        nan 0.80961977 0.81393274\n",
      "        nan 0.81276073 0.81215137        nan 0.80910431 0.80999494\n",
      "        nan 0.81374506 0.81468277        nan 0.81562036 0.81632351\n",
      "        nan 0.81782371 0.81833938        nan 0.81172925 0.81505779\n",
      "        nan 0.81360455 0.81637039        nan 0.81848003 0.81810503\n",
      "        nan 0.7781633  0.78102244        nan 0.78050739 0.77952276\n",
      "        nan 0.77896023 0.77896026        nan 0.80671338 0.80610381\n",
      "        nan 0.80732263 0.80732262        nan 0.80699465 0.80652592\n",
      "        nan 0.82016766 0.819652          nan 0.81946455 0.81951139\n",
      "        nan 0.81951145 0.81960515        nan 0.8088228  0.81266678\n",
      "        nan 0.81299511 0.81271395        nan 0.81008864 0.8117295\n",
      "        nan 0.80994789 0.81219812        nan 0.81463587 0.81552658\n",
      "        nan 0.81637051 0.81721434        nan 0.80511946 0.80760394\n",
      "        nan 0.8098543  0.81069801        nan 0.81613611 0.81468266\n",
      "        nan 0.77741318 0.77722561        nan 0.77713186 0.77755381\n",
      "        nan 0.7791945  0.77708501        nan 0.80343177 0.80652592\n",
      "        nan 0.80469743 0.80427552        nan 0.80511947 0.80633812\n",
      "        nan 0.819277   0.81890205        nan 0.81904268 0.81890207\n",
      "        nan 0.8190426  0.81941771        nan 0.80840087 0.81196373\n",
      "        nan 0.81252627 0.81252645        nan 0.81112001 0.81130762\n",
      "        nan 0.80849467 0.81285448        nan 0.81501094 0.81547974\n",
      "        nan 0.81608911 0.81735484        nan 0.80629123 0.80872906\n",
      "        nan 0.80952591 0.80990108        nan 0.81547961 0.81524533]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model:\n",
      " {'C': 0.1, 'fit_intercept': True, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "RF_clf = GridSearchCV(clf, param_grid=param_grid, n_jobs=-1, cv=5)\n",
    "RF_clf = RF_clf.fit(X_train, Y_train)\n",
    "print('The best model:\\n', grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "c3c4304c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8261766360397524\n"
     ]
    }
   ],
   "source": [
    "RF_clf = RF_clf.best_estimator_\n",
    "print(RF_clf.score(X_test,Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c6ea60c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_44 (Dense)             (None, 5)                 85        \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 3)                 18        \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 1)                 4         \n",
      "=================================================================\n",
      "Total params: 107\n",
      "Trainable params: 107\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(5, input_dim = len(X_train[0, :]), activation = 'relu'))\n",
    "\n",
    "model.add(Dense(3, activation = 'relu'))\n",
    "\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "94002ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "7111/7111 [==============================] - 7s 911us/step - loss: 0.2360 - accuracy: 0.7757 - val_loss: 0.2114 - val_accuracy: 0.7844\n",
      "Epoch 2/20\n",
      "7111/7111 [==============================] - 6s 828us/step - loss: 0.2119 - accuracy: 0.7875 - val_loss: 0.2010 - val_accuracy: 0.8071\n",
      "Epoch 3/20\n",
      "7111/7111 [==============================] - 6s 847us/step - loss: 0.1997 - accuracy: 0.8067 - val_loss: 0.1925 - val_accuracy: 0.8106\n",
      "Epoch 4/20\n",
      "7111/7111 [==============================] - 6s 845us/step - loss: 0.1934 - accuracy: 0.8092 - val_loss: 0.1893 - val_accuracy: 0.8134\n",
      "Epoch 5/20\n",
      "7111/7111 [==============================] - 6s 847us/step - loss: 0.1906 - accuracy: 0.8108 - val_loss: 0.1870 - val_accuracy: 0.8136\n",
      "Epoch 6/20\n",
      "7111/7111 [==============================] - 6s 832us/step - loss: 0.1874 - accuracy: 0.8136 - val_loss: 0.1846 - val_accuracy: 0.8172\n",
      "Epoch 7/20\n",
      "7111/7111 [==============================] - 6s 807us/step - loss: 0.1855 - accuracy: 0.8156 - val_loss: 0.1825 - val_accuracy: 0.8198\n",
      "Epoch 8/20\n",
      "7111/7111 [==============================] - 6s 845us/step - loss: 0.1845 - accuracy: 0.8162 - val_loss: 0.1829 - val_accuracy: 0.8179\n",
      "Epoch 9/20\n",
      "7111/7111 [==============================] - 6s 808us/step - loss: 0.1836 - accuracy: 0.8172 - val_loss: 0.1830 - val_accuracy: 0.8168\n",
      "Epoch 10/20\n",
      "7111/7111 [==============================] - 7s 938us/step - loss: 0.1830 - accuracy: 0.8178 - val_loss: 0.1820 - val_accuracy: 0.8189\n",
      "Epoch 11/20\n",
      "7111/7111 [==============================] - 7s 930us/step - loss: 0.1823 - accuracy: 0.8186 - val_loss: 0.1819 - val_accuracy: 0.8191\n",
      "Epoch 12/20\n",
      "7111/7111 [==============================] - 6s 811us/step - loss: 0.1816 - accuracy: 0.8186 - val_loss: 0.1821 - val_accuracy: 0.8192\n",
      "Epoch 13/20\n",
      "7111/7111 [==============================] - 6s 822us/step - loss: 0.1816 - accuracy: 0.8189 - val_loss: 0.1819 - val_accuracy: 0.8191\n",
      "Epoch 14/20\n",
      "7111/7111 [==============================] - 6s 844us/step - loss: 0.1812 - accuracy: 0.8196 - val_loss: 0.1834 - val_accuracy: 0.8161\n",
      "Epoch 15/20\n",
      "2002/7111 [=======>......................] - ETA: 4s - loss: 0.1742 - accuracy: 0.8263"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/py/5s9c0hkd3jg_qm19cvdv5ktw0000gn/T/ipykernel_19028/3057836984.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mopt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0005\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mean_absolute_error'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "opt = keras.optimizers.Adam(learning_rate=0.0005)\n",
    "model.compile(loss = 'mean_absolute_error',optimizer = opt, metrics=['accuracy'])\n",
    "model.fit(X_train, Y_train, validation_data =(X_test, Y_test), epochs = 20, batch_size = 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b71205b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c7d45afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.17946249]\n",
      " [0.1403653 ]\n",
      " [0.09882686]\n",
      " ...\n",
      " [0.08635059]\n",
      " [0.09199658]\n",
      " [0.5151571 ]]\n"
     ]
    }
   ],
   "source": [
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "049e9822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights_sgd(X_train, y_train, weights, learning_rate):\n",
    "    for X_each, y_each in zip(X_train, y_train):\n",
    "        prediction = compute_prediction(X_each, weights)\n",
    "        weights_delta = X_each.T * (y_each - prediction)\n",
    "        weights += learning_rate * weights_delta\n",
    "    return weights\n",
    "\n",
    "def train_logistic_regression_sgd(X_train, y_train, max_iter, learning_rate, fit_intercept=False):\n",
    "    if fit_intercept:\n",
    "        intercept = np.ones((X_train.shape[0], 1))\n",
    "        X_train = np.hstack((intercept, X_train))\n",
    "    weights = np.zeros(X_train.shape[1])+0.5\n",
    "    for iteration in range(max_iter):\n",
    "        weights = update_weights_sgd(X_train, y_train, weights, learning_rate)\n",
    "        # Check the cost for every 2 (for example) iterations\n",
    "        if iteration % 2 == 0:\n",
    "            print(compute_cost(X_train, y_train, weights))\n",
    "    return weights\n",
    "\n",
    "def sigmoid(input):\n",
    "    return 1.0 / (1 + np.exp(-input))\n",
    "\n",
    "def compute_prediction(X, weights):\n",
    "    z = np.dot(X, weights)\n",
    "    predictions = sigmoid(z)\n",
    "    return predictions\n",
    "\n",
    "def compute_cost(X, y, weights):\n",
    "    predictions = compute_prediction(X, weights)\n",
    "    cost = np.mean(-y * np.log(predictions) - (1 - y) * np.log(1 - predictions))\n",
    "    return cost\n",
    "\n",
    "def predict(X, weights):\n",
    "    if X.shape[1] == weights.shape[0] - 1:\n",
    "        intercept = np.ones((X.shape[0], 1))\n",
    "        X = np.hstack((intercept, X))\n",
    "    return compute_prediction(X, weights)\n",
    "\n",
    "def classification(threshold_P, X, weights):\n",
    "    vec = predict(X, weights)\n",
    "    vec = np.where(vec > threshold_P, 1, 0)\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "254764ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5691444593641837\n",
      "0.5098160404281771\n",
      "0.4974329790203034\n",
      "0.4905266530686821\n",
      "0.4857806973998171\n",
      "0.48222626783107414\n",
      "0.4794546914108589\n",
      "0.4772482367192475\n",
      "0.47547116810503115\n",
      "0.4740298215156429\n",
      "0.4728553323250336\n",
      "0.4718950922358343\n",
      "0.4711079812587019\n",
      "0.47046140700723865\n",
      "0.469929304128116\n",
      "0.4694906990905917\n",
      "0.4691286392026955\n",
      "0.4688293730589745\n",
      "0.46858171313635105\n",
      "0.46837653464283896\n",
      "0.46820637845707314\n",
      "0.46806513471988004\n",
      "0.46794778953736976\n",
      "0.46785022143044264\n",
      "0.4677690372183409\n",
      "0.46770143930638985\n",
      "0.4676451180817761\n",
      "0.46759816445310864\n",
      "0.4675589986014872\n",
      "0.4675263118157347\n",
      "0.4674990189157099\n",
      "0.4674762192649602\n",
      "0.4674571647673962\n",
      "0.467441233555022\n",
      "0.4674279083225677\n",
      "0.467416758463701\n",
      "0.4674074253228417\n",
      "0.4673996100046665\n",
      "0.46739306328659597\n",
      "0.46738757726292346\n",
      "0.467382978416764\n",
      "0.4673791218708041\n",
      "0.46737588661241114\n",
      "0.4673731715250028\n",
      "0.4673708920872518\n",
      "0.46736897762599255\n",
      "0.46736736902859594\n",
      "0.4673660168369266\n",
      "0.4673648796584334\n",
      "0.46736392284099015\n",
      "0.46736311736723\n",
      "0.46736243893164675\n",
      "0.4673618671699673\n",
      "0.46736138501544877\n",
      "0.4673609781610222\n",
      "0.46736063460974253\n",
      "0.46736034429894024\n",
      "0.4673600987859083\n",
      "0.46735989098498226\n",
      "0.4673597149475591\n",
      "0.46735956567799813\n",
      "0.4673594389795184\n",
      "0.4673593313251775\n",
      "0.4673592397498258\n",
      "0.4673591617596091\n",
      "0.46735909525615316\n",
      "0.46735903847303545\n",
      "0.46735898992254243\n",
      "0.4673589483510374\n",
      "0.4673589127015388\n",
      "0.46735888208233733\n",
      "0.46735885574067115\n",
      "0.4673588330406393\n",
      "0.46735881344466673\n",
      "0.4673587964979445\n",
      "0.46735878181536616\n",
      "0.4673587690705548\n",
      "0.4673587579866447\n",
      "0.4673587483285338\n",
      "0.46735873989637033\n",
      "0.46735873252007565\n",
      "0.4673587260547347\n",
      "0.46735872037671755\n",
      "0.4673587153804126\n",
      "0.4673587109754748\n",
      "0.46735870708450555\n",
      "0.46735870364109716\n",
      "0.4673587005881801\n",
      "0.4673586978766306\n",
      "0.4673586954640917\n",
      "0.46735869331397656\n",
      "0.4673586913946258\n",
      "0.46735868967859323\n",
      "0.46735868814204007\n",
      "0.4673586867642212\n",
      "0.46735868552704884\n",
      "0.467358684414721\n",
      "0.4673586834134059\n",
      "0.46735868251097196\n",
      "0.46735868169675865\n"
     ]
    }
   ],
   "source": [
    "weights = train_logistic_regression_sgd(X_train, Y_train, 200, 0.0001, fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "19a8634c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3782  401]\n",
      " [ 622  528]]\n",
      "0.8081755109694356\n"
     ]
    }
   ],
   "source": [
    "predictions = classification(0.3,X_test,weights)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "print(confusion_matrix(Y_test, predictions))\n",
    "print(accuracy_score(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2654dec7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
